{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Attention import MultiHeadCrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 768])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "embed_dim = 768\n",
    "num_heads = 8\n",
    "query = torch.rand(32, 20, embed_dim)  # Batch size: 32, Sequence length: 10\n",
    "key = torch.rand(32, 10, embed_dim)    # Sequence length: 20\n",
    "value = torch.rand(32, 10, embed_dim)  # Sequence length: 20\n",
    "\n",
    "multihead_cross_attention = MultiHeadCrossAttention(embed_dim, num_heads)\n",
    "output = multihead_cross_attention(query, key, value)\n",
    "print(output.shape)  # Expected output shape: (32, 10, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "embed_dim = 64\n",
    "num_heads = 8\n",
    "query = torch.rand(32, 10, embed_dim)  # Batch size: 32, Sequence length: 10\n",
    "key = torch.rand(32, 20, embed_dim)    # Sequence length: 20\n",
    "value = torch.rand(32, 20, embed_dim)  # Sequence length: 20\n",
    "\n",
    "multihead_cross_attention = MultiHeadCrossAttention(embed_dim, num_heads)\n",
    "output = multihead_cross_attention(query, key, value)\n",
    "print(output.shape)  # Expected output shape: (32, 10, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3061,  0.2622, -0.1896,  ..., -0.1651,  0.1014,  0.4119],\n",
      "         [-0.7390, -0.0336,  0.3932,  ..., -0.1818, -0.1839, -0.2185],\n",
      "         [ 0.5801,  0.0627, -0.2637,  ...,  0.3963, -0.5684, -0.4924]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# 初始化 BERT tokenizer 和模型\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 输入单词\n",
    "input_text = \"hello\"\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "# 获取模型的输出\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 获取最后一层的隐藏状态\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(last_hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"hello, my name is chris. This is my dog zoe\"\n",
    "inputs = tokenizer(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14])\n",
      "torch.Size([1, 1, 14])\n",
      "torch.Size([1, 14])\n"
     ]
    }
   ],
   "source": [
    "inputs_ids = inputs['input_ids']\n",
    "inputs_mask = inputs['attention_mask']\n",
    "print(inputs_ids.shape)\n",
    "inputs_ids = inputs_ids.unsqueeze(1)\n",
    "print(inputs_ids.shape)\n",
    "bs,rnt,sl = inputs_ids.shape\n",
    "inputs_ids = inputs_ids.view(-1,sl)\n",
    "print(inputs_ids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "torch.Size([1, 1, 768])\n",
      "torch.Size([768, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs_ids,inputs_mask)[0][:,0,:]\n",
    "print(outputs.shape)\n",
    "outputs = outputs.view(bs,rnt,-1)\n",
    "print(outputs.shape)\n",
    "outputs = outputs.permute(2,0,1)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"hello\"\n",
    "word = tokenizer(word, return_tensors='pt')\n",
    "word_ids = word['input_ids']\n",
    "word_mask = word['attention_mask']\n",
    "out_word = model(word_ids)[0][:,1,:]\n",
    "out_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ids = inputs_ids.view(-1,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 3])\n",
      "Flattened shape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个 2D 张量\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 查看原始张量的形状\n",
    "print(\"Original shape:\", tensor.shape)  # 输出: torch.Size([2, 3])\n",
    "\n",
    "# 使用 view 将其转换为 1D 张量\n",
    "flattened_tensor = tensor.view(-1,6)\n",
    "\n",
    "# 查看转换后的张量形状\n",
    "print(\"Flattened shape:\", flattened_tensor.shape)  # 输出: torch.Size([6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "Original shape: torch.Size([3])\n",
      "Expanded shape: torch.Size([5, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个1D张量\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor)\n",
    "# 查看原始张量的形状\n",
    "print(\"Original shape:\", tensor.shape)  # 输出: torch.Size([3])\n",
    "\n",
    "# 使用expand将其扩展为2D张量\n",
    "expanded_tensor = tensor.expand(5, 3)\n",
    "\n",
    "# 查看扩展后的张量形状\n",
    "print(\"Expanded shape:\", expanded_tensor.shape)  # 输出: torch.Size([2, 3])\n",
    "print(expanded_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_Attention(Q,K,V):\n",
    "    attention_weights = torch.matmul(Q,K.transpose(2,1))\n",
    "    attention_weights = F.softmax(attention_weights,-1)\n",
    "    output = torch.matmul(attention_weights, V)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context输出的维度为: torch.Size([1, 31, 768])\n",
      "gloss输出的维度为: torch.Size([1, 768])\n",
      "完成poly之后的context维度为:: torch.Size([1, 10, 768])\n",
      "gloss的维度为: torch.Size([1, 1, 768])\n",
      "gloss的维度为: torch.Size([1, 1, 768])\n",
      "扩充完的gloss的维度是: torch.Size([1, 1, 768])\n",
      "执行完注意力机制之后的ctx的维度是: torch.Size([1, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "ctx = \"Zoe is my pet dog. She is very cute. She is a golden retriever. She is 2 years old. She is very friendly.\"\n",
    "gloss = \"Zoe is a golden retriever. She is 2 years old. She is very friendly.\"\n",
    "\n",
    "ctx = tokenizer(ctx, return_tensors='pt')\n",
    "gloss = tokenizer(gloss, return_tensors='pt')\n",
    "\n",
    "ctx_ids,ctx_mask,gloss_ids,gloss_mask = ctx['input_ids'],ctx['attention_mask'],gloss['input_ids'],gloss['attention_mask']\n",
    "\n",
    "ctx_out = model(ctx_ids,ctx_mask)[0]\n",
    "print(\"context输出的维度为:\",ctx_out.shape)\n",
    "gloss_out = model(gloss_ids,gloss_mask)[0][:,0,:]\n",
    "print(\"gloss输出的维度为:\",gloss_out.shape)\n",
    "\n",
    "poly_code_ids = torch.arange(10,dtype=torch.long)\n",
    "embedding_layer = nn.Embedding(10,768)\n",
    "poly_code = embedding_layer(poly_code_ids)\n",
    "\n",
    "ctx_emd = dot_Attention(poly_code,ctx_out,ctx_out)\n",
    "print(\"完成poly之后的context维度为::\",ctx_emd.shape)\n",
    "\n",
    "gloss_out = gloss_out.view(1,1,-1)\n",
    "print(\"gloss的维度为:\",gloss_out.shape)\n",
    "gloss_emd = gloss_out.permute(1,0,2)\n",
    "print(\"gloss的维度为:\",gloss_emd.shape)\n",
    "gloss_emd = gloss_emd.expand(1,1,768)\n",
    "print(\"扩充完的gloss的维度是:\",gloss_emd.shape)\n",
    "ctx_emb = dot_Attention(gloss_emd,ctx_emd,ctx_emd)\n",
    "print(\"执行完注意力机制之后的ctx的维度是:\",ctx_emb.shape)\n",
    "gloss_emd = gloss_emd.permute(1,0,2)\n",
    "print(\"gloss转置后的维度是:\",gloss_emd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 20, 20])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_ctx = torch.rand(20,10,768)\n",
    "gloss_embedding = torch.rand(20,20,768)\n",
    "\n",
    "ctx_emb = dot_Attention(gloss_embedding,poly_ctx,poly_ctx)\n",
    "ctx_emb = ctx_emb.permute(2,0,1)\n",
    "gloss_embedding = gloss_embedding.permute(2,0,1)\n",
    "result = ctx_emb*gloss_embedding\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(10,768)\n",
    "B = torch.rand(768,10)\n",
    "C = torch.matmul(A,B)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: torch.Size([10, 40, 768])\n",
      "B shape: torch.Size([10, 768, 40])\n",
      "C shape: torch.Size([10, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建两个示例张量\n",
    "poly_n = 10\n",
    "bs,dim = 40, 768\n",
    "A = torch.randn(poly_n, bs, dim)\n",
    "B = torch.randn(poly_n, dim, bs)\n",
    "\n",
    "# 使用 torch.matmul 进行矩阵乘法\n",
    "C = torch.matmul(A, B)\n",
    "\n",
    "# 查看结果形状\n",
    "print(\"A shape:\", A.shape)  # 输出: torch.Size([2, 3, 4])\n",
    "print(\"B shape:\", B.shape)  # 输出: torch.Size([2, 4, 5])\n",
    "print(\"C shape:\", C.shape)  # 输出: torch.Size([2, 3, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([10, 768])\n"
     ]
    }
   ],
   "source": [
    "p = torch.arange(10,dtype=torch.long)\n",
    "print(p.unsqueeze(0).shape)\n",
    "embedding_layer = nn.Embedding(10,768)\n",
    "poly_code = embedding_layer(poly_code_ids)\n",
    "print(poly_code.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这一步的维度分别是为Gloss: torch.Size([40, 768]) \n",
      "和context: torch.Size([40, 10, 768])\n",
      "扩展后的gloss维度为: torch.Size([40, 10, 768])\n",
      "交叉注意力点积之后的context为: torch.Size([40, 10, 768])\n",
      "这一步的维度分别是为Gloss: torch.Size([10, 768, 40]) \n",
      "和context: torch.Size([40, 10, 768])\n",
      "最终的特征融合结果为: torch.Size([10, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "# 创建两个示例张量\n",
    "poly_n = 10\n",
    "bs,dim = 40, 768\n",
    "ctx = torch.randn(bs, poly_n, dim)\n",
    "gloss = torch.randn(bs,dim)\n",
    "print(\"这一步的维度分别是为Gloss:\",gloss.shape,\"\\n和context:\",ctx.shape)\n",
    "\n",
    "gloss = gloss.expand(poly_n,bs,dim)\n",
    "gloss = gloss.permute(1,0,2)\n",
    "print(\"扩展后的gloss维度为:\",gloss.shape)\n",
    "ctx_emb = dot_Attention(gloss,ctx,ctx)\n",
    "print(\"交叉注意力点积之后的context为:\",ctx_emb.shape)\n",
    "ctx_emb = ctx_emb.permute(1,0,2)\n",
    "gloss = gloss.permute(1,2,0)\n",
    "print(\"这一步的维度分别是为Gloss:\",gloss.shape,\"\\n和context:\",ctx.shape)\n",
    "representation = torch.matmul(ctx_emb,gloss)\n",
    "print(\"最终的特征融合结果为:\",representation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctx_output的维度为: torch.Size([3, 8, 768])\n",
      "gloss_output的维度为: torch.Size([3, 768])\n",
      "wprd_output的维度为: torch.Size([3, 768])\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "poly_code的维度为: torch.Size([10, 768])\n",
      "ctx_emb的维度为: torch.Size([3, 10, 768])\n",
      "gloss_emb的维度为: torch.Size([3, 10, 768])\n",
      "words_emb的维度为: torch.Size([3, 10, 768])\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "ctx_emb的维度为: torch.Size([3, 10, 768])\n",
      "representation的维度为: torch.Size([10, 3, 3])\n",
      "representation的维度为: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 你的测试句子列表\n",
    "sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Transformers are very powerful.\",\n",
    "    \"Do you like machine learning?\"\n",
    "]\n",
    "\n",
    "glosses= [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Transformers are very powerful.\",\n",
    "    \"Do you like machine learning?\"\n",
    "]\n",
    "\n",
    "words = [\n",
    "    \"hello\",\n",
    "    \"joe\",\n",
    "    \"bye\"\n",
    "]\n",
    "\n",
    "\n",
    "# 使用分词器处理文本数据\n",
    "\n",
    "ctx_inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "gloss_inputs = tokenizer(glosses, padding=True, truncation=True, return_tensors='pt')\n",
    "words_inputs = tokenizer(words, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# 推理，获取隐藏状态\n",
    "with torch.no_grad():\n",
    "    ctx_output = model(**ctx_inputs)[0]\n",
    "    gloss_output = model(**gloss_inputs)[0][:,0,:]\n",
    "    words_output = model(words_inputs[\"input_ids\"])[0][:,1,:]\n",
    "\n",
    "print(\"ctx_output的维度为:\",ctx_output.shape)\n",
    "print(\"gloss_output的维度为:\",gloss_output.shape)\n",
    "print(\"wprd_output的维度为:\",words_output.shape)\n",
    "print(\"++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "poly_code_ids = torch.arange(10,dtype=torch.long)\n",
    "embedding_layer = nn.Embedding(10,768)\n",
    "poly_code = embedding_layer(poly_code_ids)\n",
    "print(\"poly_code的维度为:\",poly_code.shape)\n",
    "ctx_emb = dot_Attention(poly_code,ctx_output,ctx_output)\n",
    "print(\"ctx_emb的维度为:\",ctx_emb.shape)\n",
    "\n",
    "gloss_emb = gloss_output.expand(10,3,768).transpose(0, 1)\n",
    "#gloss_emb = gloss_emb.permute(1,0,2)\n",
    "print(\"gloss_emb的维度为:\",gloss_emb.shape)\n",
    "\n",
    "words_emb = words_output.expand(10,3,768).transpose(0, 1)\n",
    "print(\"words_emb的维度为:\",words_emb.shape)\n",
    "print(\"++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "gloss_emb = multihead_cross_attention(words_emb,gloss_emb,gloss_emb)\n",
    "context_emb = multihead_cross_attention(words_emb,ctx_emb,ctx_emb)\n",
    "\n",
    "\n",
    "ctx_emb = dot_Attention(gloss_emb,ctx_emb,ctx_emb)\n",
    "print(\"ctx_emb的维度为:\",ctx_emb.shape)\n",
    "\n",
    "ctx_emb = ctx_emb.permute(1,0,2)\n",
    "gloss_emb = gloss_emb.permute(1,2,0)\n",
    "representation = torch.matmul(ctx_emb,gloss_emb)\n",
    "print(\"representation的维度为:\",representation.shape)\n",
    "representation = representation.sum(0)\n",
    "print(\"representation的维度为:\",representation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gloss_ids的维度为: torch.Size([3, 1, 8])\n",
      "bs,rnt,sl的维度为: 3 1 8\n",
      "gloss_ids的维度为: torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "gloss_ids = gloss_inputs[\"input_ids\"]\n",
    "gloss_ids = gloss_ids.unsqueeze(1)\n",
    "print(\"gloss_ids的维度为:\",gloss_ids.shape)\n",
    "bs,rnt,sl = gloss_ids.shape\n",
    "print(\"bs,rnt,sl的维度为:\",bs,rnt,sl)\n",
    "gloss_ids = gloss_ids.squeeze(1)\n",
    "print(\"gloss_ids的维度为:\",gloss_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly_codes_ids的维度为: torch.Size([10])\n",
      "poly_codes的维度为: torch.Size([10, 768])\n",
      "poly_codes_ids的维度为: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "poly_codes_ids = torch.arange(10,dtype=torch.long)\n",
    "embedding_layer = nn.Embedding(10,768)\n",
    "print(\"poly_codes_ids的维度为:\",poly_codes_ids.shape)\n",
    "poly_codes = embedding_layer(poly_codes_ids)\n",
    "print(\"poly_codes的维度为:\",poly_codes.shape)\n",
    "\n",
    "poly_codes_ids = poly_codes_ids.expand(bs,10)\n",
    "print(\"poly_codes_ids的维度为:\",poly_codes_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
